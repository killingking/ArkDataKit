import asyncio
import json
import re
import string
from datetime import datetime
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from bs4 import BeautifulSoup

# --- å…¨å±€é…ç½®ï¼ˆé›†ä¸­ç®¡ç†ï¼Œæ–¹ä¾¿ä¿®æ”¹ï¼‰---
class Config:
    BASE_URL = "https://prts.wiki"
    HEADLESS = True  # è°ƒè¯•æ—¶å¯æ”¹ä¸ºFalseï¼ŒæŸ¥çœ‹æµè§ˆå™¨æ“ä½œ
    LOG_FILE = "prts_parse_debug.log"
    # è¶…æ—¶é…ç½®ï¼ˆç»Ÿä¸€ç®¡ç†ï¼Œé¿å…ç¡¬ç¼–ç ï¼‰
    PAGE_LOAD_TIMEOUT = 20000  # é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆ20ç§’ï¼‰
    LOCATOR_WAIT_TIMEOUT = 3000  # å…ƒç´ ç­‰å¾…è¶…æ—¶ï¼ˆ3ç§’ï¼‰
    TEXT_EXTRACT_TIMEOUT = 1500  # æ–‡æœ¬æå–è¶…æ—¶ï¼ˆ1.5ç§’ï¼‰
    # ç­‰å¾…æ—¶é—´é…ç½®ï¼ˆå¹³è¡¡æ•ˆç‡å’Œç¨³å®šæ€§ï¼‰
    TOOLTIP_RENDER_WAIT = 1.2  # æç¤ºæ¡†æ¸²æŸ“ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    MOUSE_MOVE_WAIT = 0.6  # ç§»å¼€é¼ æ ‡åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    # æœ¯è¯­è¿‡æ»¤é…ç½®
    TERM_MIN_LENGTH = 2  # æœ¯è¯­åæœ€å°é•¿åº¦
    DESC_MIN_LENGTH = 5  # æè¿°æœ€å°é•¿åº¦
    # æç¤ºæ¡†é€‰æ‹©å™¨ï¼ˆè¦†ç›–PRTSå¸¸è§æç¤ºæ¡†ç»“æ„ï¼‰
    TOOLTIP_SELECTORS = [
        '[role="tooltip"]',
        ".tippy-box",
        ".tippy-content",
        ".tooltip-content",
        ".mw-tooltip",
        ".mc-tooltip-content"
    ]

# --- å·¥å…·å‡½æ•°ï¼ˆæå–é‡å¤é€»è¾‘ï¼Œæå‡å¤ç”¨æ€§ï¼‰---
def log_debug(message: str):
    """è®°å½•è°ƒè¯•ä¿¡æ¯ï¼ˆå«æ—¶é—´æˆ³ï¼Œæ–¹ä¾¿æ’æŸ¥ï¼‰"""
    with open(Config.LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"{datetime.now().isoformat()} | {message}\n")

def _txt(tag) -> str:
    """ç»Ÿä¸€æ–‡æœ¬æå–å‡½æ•°ï¼ˆé¿å…é‡å¤åˆ¤æ–­ï¼‰"""
    if not tag:
        return ""
    return tag.get_text(strip=True).replace("ï¼ˆ+ï¼‰", "").strip()

def _clean_desc(tag) -> str:
    """ç»Ÿä¸€æè¿°æ¸…ç†å‡½æ•°ï¼ˆå‰”é™¤æ— ç”¨æ ‡ç­¾ï¼‰"""
    if not tag:
        return ""
    # å‰”é™¤ç®—æ³•æç¤ºã€é¢œè‰²span
    for bad_span in tag.select(
        'span[style*="color:#0098DC"], '
        'span[style*="color:green"], '
        'span[style*="color:#007DFA"], '
        'span[style*="display:none"]'
    ):
        bad_span.replace_with("")
    return _txt(tag)

def clean_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åç‰¹æ®Šå­—ç¬¦ï¼ˆé¿å…ä¿å­˜å¤±è´¥ï¼‰"""
    invalid_chars = set(string.punctuation.replace("_", "") + r":\/?*<>|")
    return "".join(c if c not in invalid_chars else "_" for c in name)

# --- å¹²å‘˜è§£ææ ¸å¿ƒç±» ---
class SingleOperatorParser:
    def __init__(self, page):
        self.page = page
        self.soup = None  # BeautifulSoupå¯¹è±¡ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰

    async def get_soup(self):
        """å»¶è¿Ÿåˆå§‹åŒ–Soupå¯¹è±¡ï¼ˆé¿å…é‡å¤è·å–é¡µé¢å†…å®¹ï¼‰"""
        if not self.soup:
            content = await self.page.content()
            self.soup = BeautifulSoup(content, "lxml")
        return self.soup

    async def parse_attrs(self):
        """è§£æå±æ€§è¡¨ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œä¼˜åŒ–å˜é‡å‘½åï¼‰"""
        await self.get_soup()
        # åˆå§‹åŒ–åŸºç¡€å±æ€§ç»“æ„ï¼ˆä¼˜åŒ–å­—å…¸æ¨å¯¼å¼ï¼Œæ›´ç®€æ´ï¼‰
        base_attrs = {
            "elite_0_level_1": {},
            "elite_0_max": {},
            "elite_1_max": {},
            "elite_2_max": {},
            "trust_bonus": {}
        }
        base_tbl = self.soup.select_one("table.char-base-attr-table")
        
        if base_tbl:
            headers = [_txt(th) for th in base_tbl.select("tr:first-child th, tr:first-child td")]
            # ä¼˜åŒ–è¡¨å¤´æ˜ å°„é€»è¾‘ï¼ˆç”¨åˆ—è¡¨æ¨å¯¼å¼æ›¿ä»£å¾ªç¯ï¼‰
            key_mapping = [
                "elite_0_level_1" if "ç²¾è‹±0 1çº§" in h else
                "elite_0_max" if "ç²¾è‹±0 æ»¡çº§" in h else
                "elite_1_max" if "ç²¾è‹±1 æ»¡çº§" in h else
                "elite_2_max" if "ç²¾è‹±2 æ»¡çº§" in h else
                "trust_bonus" if "ä¿¡èµ–åŠ æˆä¸Šé™" in h else
                "" for h in headers
            ]
            attr_mapping = {"ç”Ÿå‘½ä¸Šé™": "max_hp", "æ”»å‡»": "atk", "é˜²å¾¡": "def", "æ³•æœ¯æŠ—æ€§": "res"}
            
            # è§£æå±æ€§è¡Œï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
            for tr in base_tbl.select("tr")[1:]:
                tds = [_txt(td) for td in tr.select("th, td")]
                if len(tds) < 2:
                    continue
                attr_key = attr_mapping.get(tds[0], tds[0].lower())
                # å¡«å……å±æ€§å€¼ï¼ˆä¼˜åŒ–ç´¢å¼•é€»è¾‘ï¼‰
                for idx, val in enumerate(tds[1:], 1):
                    if idx < len(key_mapping) and key_mapping[idx]:
                        base_attrs[key_mapping[idx]][attr_key] = val

        # è§£æé¢å¤–å±æ€§
        extra_attrs = {}
        extra_tbl = self.soup.select_one("table.char-extra-attr-table")
        extra_key_map = {
            "å†éƒ¨ç½²æ—¶é—´": "redployment_time",
            "åˆå§‹éƒ¨ç½²è´¹ç”¨": "initial_deployment_cost",
            "æ”»å‡»é—´éš”": "attack_interval",
            "é˜»æŒ¡æ•°": "block_count",
            "æ‰€å±åŠ¿åŠ›": "faction",
            "éšè—åŠ¿åŠ›": "hidden_faction"
        }
        
        if extra_tbl:
            for tr in extra_tbl.select("tr"):
                cells = [_txt(cell) for cell in tr.select("th, td")]
                # æŒ‰ä¸¤ä¸¤åˆ†ç»„è§£æï¼ˆé¿å…ç´¢å¼•è¶Šç•Œï¼‰
                for i in range(0, len(cells) - 1, 2):
                    raw_key, val = cells[i], cells[i+1]
                    extra_attrs[extra_key_map.get(raw_key, raw_key)] = val

        return {"base_attributes": base_attrs, "extra_attributes": extra_attrs}

    async def parse_chara(self):
        """è§£æç‰¹æ€§å’Œåˆ†æ”¯ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œä¼˜åŒ–ç©ºå€¼å¤„ç†ï¼‰"""
        await self.get_soup()
        result = {
            "branch_name": "",
            "branch_description": "",
            "trait_details": ""
        }
        trait_tbl = self.soup.select_one("table.wikitable.logo")
        
        if trait_tbl:
            rows = trait_tbl.select("tr")
            # è§£æåˆ†æ”¯åç§°å’Œæè¿°ï¼ˆä¼˜åŒ–ç´¢å¼•åˆ¤æ–­ï¼‰
            if len(rows) > 1:
                tds = rows[1].find_all("td")
                result["branch_name"] = _txt(tds[0]) if tds else ""
                result["branch_description"] = _txt(tds[1]) if len(tds) > 1 else ""
            
            # è§£æåˆ†æ”¯è¯¦æƒ…ï¼ˆä¼˜åŒ–æŸ¥æ‰¾é€»è¾‘ï¼‰
            branch_row = trait_tbl.find("tr", string=re.compile("åˆ†æ”¯ä¿¡æ¯"))
            if branch_row:
                next_row = branch_row.find_next_sibling("tr")
                if next_row:
                    result["trait_details"] = "".join(_clean_desc(li) for li in next_row.select("li"))

        return result

    async def parse_talents(self):
        """è§£æå¤©èµ‹ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œä¼˜åŒ–é‡å¤ä»£ç ï¼‰"""
        await self.get_soup()
        talents = []
        talent_header = self.soup.find("span", id="å¤©èµ‹")
        if not talent_header:
            log_debug("æœªæ‰¾åˆ°å¤©èµ‹åŒºåŸŸ")
            return talents

        def parse_single_talent(table, talent_type: str, span_prefix: str) -> dict:
            """æå–å•ä¸ªå¤©èµ‹ï¼ˆä¼˜åŒ–å˜é‡åˆå§‹åŒ–ï¼‰"""
            talent = {
                "talent_type": talent_type,
                "talent_name": "",
                "remarks": "",
                "details": []
            }
            rows = table.find_all("tr")
            is_remark_section = False
            remark_text = ""

            for idx, row in enumerate(rows):
                if idx == 0:
                    continue  # è·³è¿‡è¡¨å¤´
                tds = row.find_all("td")
                th = row.find("th")

                # åˆ¤æ–­æ˜¯å¦ä¸ºå¤‡æ³¨è¡Œ
                if idx == len(rows) - 2 and th:
                    is_remark_section = True
                    continue
                if not tds:
                    continue

                # å¤„ç†å¤‡æ³¨
                if is_remark_section:
                    remark_text = _txt(tds[0])
                    break

                # æå–å¤©èµ‹åç§°ï¼ˆä»…é¦–æ¬¡èµ‹å€¼ï¼‰
                current_name = _txt(tds[0])
                if not talent["talent_name"] and current_name:
                    talent["talent_name"] = current_name

                # æå–å¤©èµ‹è¯¦æƒ…ï¼ˆä¼˜åŒ–é€‰æ‹©å™¨é€»è¾‘ï¼‰
                talent["details"].append({
                    "trigger_condition": _txt(tds[1]),
                    "description": _clean_desc(tds[2].select_one(f"span.{span_prefix}æ½œèƒ½_1")),
                    "potential_enhancement": _clean_desc(tds[2].select_one(f"span.{span_prefix}æ½œèƒ½_2"))
                })

            talent["remarks"] = remark_text
            return talent if talent["talent_name"] and talent["details"] else None

        # è§£æç¬¬ä¸€å¤©èµ‹
        first_talent_tbl = talent_header.find_next("table", class_="wikitable")
        if first_talent_tbl:
            first_talent = parse_single_talent(first_talent_tbl, "ç¬¬ä¸€å¤©èµ‹", "ç¬¬ä¸€å¤©èµ‹")
            if first_talent:
                talents.append(first_talent)

        # è§£æç¬¬äºŒå¤©èµ‹ï¼ˆä¼˜åŒ–ç©ºå€¼åˆ¤æ–­ï¼‰
        second_talent_tbl = first_talent_tbl.find_next_sibling("table", class_="wikitable") if first_talent_tbl else None
        if second_talent_tbl:
            second_talent = parse_single_talent(second_talent_tbl, "ç¬¬äºŒå¤©èµ‹", "ç¬¬äºŒå¤©èµ‹")
            if second_talent:
                talents.append(second_talent)

        log_debug(f"è§£æåˆ°å¤©èµ‹æ•°é‡ï¼š{len(talents)}")
        return talents

    async def parse_skills(self):
        """è§£ææŠ€èƒ½ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œä¼˜åŒ–é”™è¯¯å¤„ç†ï¼‰"""
        await self.get_soup()
        skills = []
        skill_header = self.soup.find("span", id="æŠ€èƒ½")
        
        if not skill_header:
            log_debug("æœªæ‰¾åˆ°æŠ€èƒ½åŒºåŸŸ")
            return skills

        # æå–å¯è§æ–‡æœ¬ï¼ˆä¼˜åŒ–å‡½æ•°å‘½åå’Œé€»è¾‘ï¼‰
        def extract_visible_text(td_elem) -> str:
            visible_parts = []
            for child in td_elem.contents:
                if isinstance(child, str):
                    stripped = child.strip()
                    if stripped:
                        visible_parts.append(stripped)
                elif child.name == "span" and "display:none" not in child.get("style", ""):
                    span_text = child.get_text(strip=True)
                    if span_text:
                        visible_parts.append(span_text)
            return " ".join(visible_parts)

        # è§£æå•ä¸ªæŠ€èƒ½ï¼ˆä¼˜åŒ–å‚æ•°å‘½åï¼‰
        def parse_single_skill(table, skill_idx: int) -> dict:
            skill = {
                "skill_number": skill_idx,
                "skill_name": "",
                "skill_type": "",
                "unlock_condition": f"ç²¾è‹±{skill_idx}",
                "remark": "",
                "skill_levels": []
            }
            rows = table.find_all("tr")
            is_remark = False

            for idx, row in enumerate(rows):
                tds = row.find_all("td")
                if idx == 0:
                    # æå–æŠ€èƒ½åç§°ï¼ˆä¼˜åŒ–æŸ¥æ‰¾é€»è¾‘ï¼‰
                    big_tag = tds[1].find("big")
                    skill["skill_name"] = _txt(big_tag) if big_tag else _txt(tds[1])
                    # æå–æŠ€èƒ½ç±»å‹ï¼ˆä¼˜åŒ–åˆ—è¡¨æ¨å¯¼å¼ï¼‰
                    tooltip_spans = tds[2].find_all("span", class_="mc-tooltips")
                    skill["skill_type"] = "|".join(
                        [_txt(span) for span in tooltip_spans if _txt(span)]
                    )
                    continue

                # æå–å…³é”®ç­‰çº§ï¼ˆ7çº§å’Œä¸“ç²¾3ï¼‰
                if idx == 8 or idx == 11:
                    if len(tds) >= 5:
                        skill["skill_levels"].append({
                            "level": _txt(tds[0]),
                            "description": extract_visible_text(tds[1]),
                            "initial_sp": _txt(tds[2]),
                            "sp_cost": _txt(tds[3]),
                            "duration": _txt(tds[4])
                        })
                    continue

                # è¯†åˆ«å¤‡æ³¨è¡Œ
                if idx == len(rows) - 2 and row.find("th"):
                    is_remark = True
                    continue
                if is_remark:
                    skill["remark"] = _txt(tds[0])
                    break

            return skill

        # è§£æ3ä¸ªæŠ€èƒ½ï¼ˆä¼˜åŒ–å¾ªç¯é€»è¾‘ï¼Œé¿å…é‡å¤ä»£ç ï¼‰
        current_table = skill_header.find_parent("h2").find_next_sibling("table")
        skill_tables = []
        for _ in range(3):
            if current_table and "wikitable" in current_table.get("class", []):
                skill_tables.append(current_table)
                current_table = current_table.find_next_sibling("table", class_="wikitable nomobile logo")
            else:
                log_debug(f"æœªæ‰¾åˆ°ç¬¬{len(skill_tables)+1}ä¸ªæŠ€èƒ½è¡¨æ ¼")
                break

        # æ‰¹é‡è§£ææŠ€èƒ½
        for idx, table in enumerate(skill_tables, 1):
            skills.append(parse_single_skill(table, idx))

        log_debug(f"è§£æåˆ°æŠ€èƒ½æ•°é‡ï¼š{len(skills)}")
        return skills

    async def parse_terms(self):
        """æœ€ç»ˆè·‘é€šç‰ˆæœ¯è¯­è§£æï¼ˆæ— é‡å¤å®šä¹‰ï¼Œä¼˜åŒ–é…ç½®ä¾èµ–ï¼‰"""
        await self.get_soup()
        terms = []
        term_seen = set()
        total_success = 0
        total_failed = 0

        try:
            # 1. å®šä½æ ¸å¿ƒå†…å®¹åŒº
            content_div = self.soup.find("div", id="mw-content-text")
            if not content_div:
                log_debug("æœªæ‰¾åˆ°æ ¸å¿ƒå†…å®¹åŒºï¼Œè·³è¿‡æœ¯è¯­æå–")
                print("âš ï¸  æœªæ‰¾åˆ°æ ¸å¿ƒå†…å®¹åŒºï¼Œè·³è¿‡æœ¯è¯­æå–")
                return terms

            # 2. ç­›é€‰æœ‰æ•ˆæœ¯è¯­æ ‡ç­¾ï¼ˆä¾èµ–å…¨å±€é…ç½®ï¼Œæ–¹ä¾¿è°ƒæ•´ï¼‰
            term_tags = content_div.find_all(
                lambda tag: tag.name == "span"
                and tag.get("class")
                and any("mc-tooltips" in c for c in tag.get("class"))
                and len(_txt(tag).strip()) >= Config.TERM_MIN_LENGTH
                and not _txt(tag).strip().isdigit()
            )
            total_terms = len(term_tags)
            print(f"\nğŸ” æœ¯è¯­æå–å¼€å§‹ï¼šå…±æ‰¾åˆ° {total_terms} ä¸ªæœ‰æ•ˆæ½œåœ¨æœ¯è¯­æ ‡ç­¾")
            if total_terms == 0:
                return terms

            # 3. é€ä¸ªå¤„ç†æœ¯è¯­
            for idx, term_tag in enumerate(term_tags, 1):
                term_name = _txt(term_tag).strip()
                # è·³è¿‡é‡å¤æˆ–æ— æ•ˆæœ¯è¯­
                if not term_name or term_name in term_seen:
                    print(f"â­ï¸  æœ¯è¯­{idx}/{total_terms}ï¼šè·³è¿‡ï¼ˆé‡å¤/æ— æ•ˆï¼‰â†’ åç§°ï¼š{term_name}")
                    continue

                try:
                    # 3.1 æ„å»ºCSSå®šä½å™¨ï¼ˆä¼˜åŒ–ç‰¹æ®Šå­—ç¬¦å¤„ç†ï¼‰
                    class_list = term_tag.get("class", [])
                    valid_classes = [c for c in class_list if "mc-tooltips" in c]
                    if not valid_classes:
                        print(f"â­ï¸  æœ¯è¯­{idx}/{total_terms}ï¼šè·³è¿‡ï¼ˆæ— æœ‰æ•ˆclassï¼‰â†’ åç§°ï¼š{term_name}")
                        total_failed += 1
                        continue

                    term_class = valid_classes[0]
                    # å¤„ç†å•å¼•å·ã€åŒå¼•å·ã€åæ–œæ ç­‰ç‰¹æ®Šå­—ç¬¦
                    safe_name = term_name.replace("'", "\\'").replace('"', '\\"').replace("\\", "\\\\")
                    css_selector = f"span.{term_class}:has-text('{safe_name}')"
                    locator = self.page.locator(css_selector).first  # ä»…å–ç¬¬ä¸€ä¸ªï¼Œé¿å…ä¸¥æ ¼æ¨¡å¼æŠ¥é”™

                    # è°ƒè¯•ï¼šæ‰“å°åŒ¹é…æ•°é‡
                    match_count = await self.page.locator(css_selector).count()
                    if match_count > 1:
                        log_debug(f"æœ¯è¯­{term_name}åŒ¹é…{match_count}ä¸ªå…ƒç´ ï¼Œå–ç¬¬ä¸€ä¸ª")
                        print(f"âš ï¸  æœ¯è¯­{idx}/{total_terms}ï¼šå®šä½å™¨åŒ¹é…{match_count}ä¸ªå…ƒç´ ï¼Œå·²å–ç¬¬ä¸€ä¸ª â†’ åç§°ï¼š{term_name}")

                    # 3.2 æ‚¬æµ®è§¦å‘æç¤ºæ¡†ï¼ˆä¾èµ–é…ç½®é¡¹ï¼Œç»Ÿä¸€ç®¡ç†ï¼‰
                    await locator.wait_for(state="visible", timeout=Config.LOCATOR_WAIT_TIMEOUT)
                    await locator.scroll_into_view_if_needed()
                    await locator.hover(force=True)
                    await asyncio.sleep(Config.TOOLTIP_RENDER_WAIT)  # ç»™è¶³æ¸²æŸ“æ—¶é—´

                    # 3.3 æå–æç¤ºæ¡†å†…å®¹ï¼ˆä¼˜åŒ–å¾ªç¯é€»è¾‘ï¼‰
                    term_type = "æ— "
                    term_desc = ""
                    tip_found = False

                    for tip_selector in Config.TOOLTIP_SELECTORS:
                        tip_locator = self.page.locator(tip_selector).first
                        if await tip_locator.count() > 0:
                            tip_found = True
                            # æå–<strong>å†…å®¹ï¼ˆæœ¯è¯­ç±»å‹ï¼‰
                            strong_handles = await tip_locator.locator("strong").all()
                            strong_texts = []
                            for handle in strong_handles:
                                text = await handle.inner_text(timeout=Config.TEXT_EXTRACT_TIMEOUT)
                                clean_text = text.strip().split(":")[0].rstrip("ï¼š:")
                                if clean_text:
                                    strong_texts.append(clean_text)
                            term_type = "ï¼Œ".join(strong_texts) if strong_texts else "æ— "
                            # é¿å…ç±»å‹ä¸åç§°é‡å¤
                            if term_type == term_name:
                                term_type = "æ— "

                            # æå–æ­£æ–‡ï¼ˆæ’é™¤strongï¼‰
                            content_handles = await tip_locator.locator(":not(strong)").all()
                            content_parts = []
                            for handle in content_handles:
                                text = await handle.inner_text(timeout=Config.TEXT_EXTRACT_TIMEOUT)
                                clean_text = text.strip()
                                if clean_text:
                                    content_parts.append(clean_text)
                            term_desc = "\n".join(content_parts) if content_parts else ""

                            # æ­£æ–‡ä¸ºç©ºæ—¶å–å®Œæ•´æ–‡æœ¬
                            if not term_desc:
                                full_text = await tip_locator.inner_text(timeout=Config.TEXT_EXTRACT_TIMEOUT)
                                if term_type != "æ— ":
                                    full_text = full_text.replace(f"{term_type}ï¼š", "").replace(f"{term_type}:", "").replace(term_type, "")
                                term_desc = full_text.strip()
                            break

                    if not tip_found:
                        log_debug(f"æœ¯è¯­{term_name}æœªæ‰¾åˆ°æç¤ºæ¡†")
                        print(f"âŒ æœ¯è¯­{idx}/{total_terms}ï¼šå¤±è´¥ï¼ˆæœªæ‰¾åˆ°æç¤ºæ¡†ï¼‰â†’ åç§°ï¼š{term_name}")
                        total_failed += 1
                        continue

                    # 3.4 è¿‡æ»¤æ— æ•ˆæè¿°
                    formatted_desc = re.sub(r"\s+", "\n", term_desc).strip()
                    if len(formatted_desc) < Config.DESC_MIN_LENGTH:
                        log_debug(f"æœ¯è¯­{term_name}æè¿°è¿‡çŸ­ï¼ˆ{len(formatted_desc)}å­—ï¼‰ï¼Œè·³è¿‡")
                        print(f"â­ï¸  æœ¯è¯­{idx}/{total_terms}ï¼šè·³è¿‡ï¼ˆæè¿°è¿‡çŸ­ï¼‰â†’ åç§°ï¼š{term_name}")
                        total_failed += 1
                        continue

                    # 3.5 åŠ å…¥ç»“æœï¼ˆå»é‡ï¼‰
                    if term_name not in term_seen:
                        terms.append({
                            "term_name": term_name,
                            "term_type": term_type,
                            "term_description": formatted_desc
                        })
                        term_seen.add(term_name)
                        total_success += 1
                        print(f"âœ… æœ¯è¯­{idx}/{total_terms}ï¼šæˆåŠŸ â†’ åç§°ï¼š{term_name} | ç±»å‹ï¼š{term_type} | æè¿°é•¿åº¦ï¼š{len(formatted_desc)}å­—")

                    # 3.6 æ¸…ç†çŠ¶æ€ï¼ˆé¿å…å½±å“ä¸‹ä¸€ä¸ªæœ¯è¯­ï¼‰
                    await self.page.mouse.move(100, 100)
                    await asyncio.sleep(Config.MOUSE_MOVE_WAIT)

                # ç²¾å‡†æ•è·é”™è¯¯ï¼ˆä¼˜åŒ–é”™è¯¯æ—¥å¿—ï¼‰
                except PlaywrightTimeoutError:
                    log_debug(f"æœ¯è¯­{term_name}æå–è¶…æ—¶")
                    print(f"âŒ æœ¯è¯­{idx}/{total_terms}ï¼šå¤±è´¥ï¼ˆè¶…æ—¶ï¼‰â†’ åç§°ï¼š{term_name}")
                    total_failed += 1
                    continue
                except AttributeError as e:
                    log_debug(f"æœ¯è¯­{term_name}å±æ€§é”™è¯¯ï¼š{str(e)[:50]}")
                    print(f"âŒ æœ¯è¯­{idx}/{total_terms}ï¼šå¤±è´¥ï¼ˆå±æ€§é”™è¯¯ï¼‰â†’ åç§°ï¼š{term_name} | é”™è¯¯ï¼š{str(e)[:50]}")
                    total_failed += 1
                    continue
                except Exception as e:
                    log_debug(f"æœ¯è¯­{term_name}æœªçŸ¥é”™è¯¯ï¼š{str(e)[:50]}")
                    print(f"âŒ æœ¯è¯­{idx}/{total_terms}ï¼šå¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰â†’ åç§°ï¼š{term_name} | é”™è¯¯ï¼š{str(e)[:50]}")
                    total_failed += 1
                    continue

        except Exception as e:
            log_debug(f"æœ¯è¯­æå–ä¸»æµç¨‹é”™è¯¯ï¼š{str(e)}")
            print(f"\nâš ï¸  æœ¯è¯­æå–ä¸»æµç¨‹é”™è¯¯ï¼š{str(e)}")

        # æœ€ç»ˆå»é‡ï¼ˆåŒé‡ä¿éšœï¼‰
        unique_terms = []
        final_seen = set()
        for term in terms:
            if term["term_name"] not in final_seen:
                final_seen.add(term["term_name"])
                unique_terms.append(term)

        # æ‰“å°ç»Ÿè®¡æŠ¥å‘Š
        print(f"\nğŸ“Š æœ¯è¯­æå–å®Œæˆï¼šæ€»è®¡{total_terms}ä¸ªæœ‰æ•ˆæ½œåœ¨æœ¯è¯­ â†’ æˆåŠŸ{total_success}ä¸ª | å¤±è´¥{total_failed}ä¸ª | å»é‡å{len(unique_terms)}ä¸ª")
        log_debug(f"æœ¯è¯­æå–ç»Ÿè®¡ï¼šæ€»è®¡{total_terms} | æˆåŠŸ{total_success} | å¤±è´¥{total_failed} | å»é‡å{len(unique_terms)}")
        return unique_terms

    async def parse_all(self, operator_name: str):
        """ä¸»è§£æå…¥å£ï¼ˆä¼˜åŒ–è¿”å›ç»“æ„ï¼Œç»Ÿä¸€æ ¼å¼ï¼‰"""
        return {
            "operator_name": operator_name,
            "metadata": {
                "last_updated": datetime.now().isoformat(),
                "source": Config.BASE_URL,
                "version": "v10.0",
                "parser_config": {
                    "headless": Config.HEADLESS,
                    "term_min_length": Config.TERM_MIN_LENGTH,
                    "desc_min_length": Config.DESC_MIN_LENGTH
                }
            },
            "characteristic": await self.parse_chara(),
            "attributes": await self.parse_attrs(),
            "talents": await self.parse_talents(),
            "skills": await self.parse_skills(),
            "terms": await self.parse_terms()
        }

# --- å¤–éƒ¨è°ƒç”¨å…¥å£ ---
async def parse_single_operator(operator_name: str):
    """è§£æå•ä¸ªå¹²å‘˜ï¼ˆä¼˜åŒ–é”™è¯¯å¤„ç†å’Œæ–‡ä»¶ä¿å­˜ï¼‰"""
    operator_name = operator_name.strip()
    if not operator_name:
        log_debug("å¹²å‘˜åç§°ä¸ºç©ºï¼Œè·³è¿‡è§£æ")
        print("âŒ å¹²å‘˜åç§°ä¸ºç©ºï¼Œæ— æ³•è§£æ")
        return None

    url = f"{Config.BASE_URL}/w/{operator_name}"
    print(f"--- å¼€å§‹çˆ¬å–å¹²å‘˜: {operator_name} ({url}) ---")
    log_debug(f"å¼€å§‹çˆ¬å–å¹²å‘˜ï¼š{operator_name}ï¼ŒURLï¼š{url}")

    async with async_playwright() as p:
        try:
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆä¼˜åŒ–å¯åŠ¨å‚æ•°ï¼‰
            browser = await p.chromium.launch(
                headless=Config.HEADLESS,
                args=["--no-sandbox", "--disable-dev-shm-usage"]  # é€‚é…Linuxç¯å¢ƒ
            )
            page = await browser.new_page()

            # é¡µé¢åŠ è½½ï¼ˆä¼˜åŒ–ç­‰å¾…é€»è¾‘ï¼‰
            await page.goto(url, wait_until="domcontentloaded")
            await page.wait_for_selector("#mw-content-text", timeout=Config.PAGE_LOAD_TIMEOUT)
            log_debug(f"é¡µé¢åŠ è½½å®Œæˆï¼š{url}")

            # æ‰§è¡Œè§£æ
            parser = SingleOperatorParser(page)
            result = await parser.parse_all(operator_name)

            # ä¿å­˜ç»“æœï¼ˆä¼˜åŒ–æ–‡ä»¶åå’ŒIOé”™è¯¯å¤„ç†ï¼‰
            safe_filename = clean_filename(operator_name)
            output_path = f"{safe_filename}.json"
            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"âœ… æˆåŠŸä¿å­˜: {output_path}")
                log_debug(f"ç»“æœä¿å­˜æˆåŠŸï¼š{output_path}")
            except IOError as e:
                log_debug(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
                print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")

            # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆä¼˜åŒ–æ ¼å¼ï¼‰
            print("\n=== è§£æç»“æœæ±‡æ€» ===")
            print(f"å¹²å‘˜åç§°: {result['operator_name']}")
            print(f"åˆ†æ”¯åç§°: {result['characteristic']['branch_name']}")
            print(f"å¤©èµ‹æ•°é‡: {len(result['talents'])}")
            print(f"æŠ€èƒ½æ•°é‡: {len(result['skills'])}")
            print(f"æœ¯è¯­æ•°é‡: {len(result['terms'])}")
            print("====================")

            return result

        except PlaywrightTimeoutError:
            log_debug(f"çˆ¬å–{operator_name}è¶…æ—¶ï¼š{url}")
            print(f"âŒ é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆ{Config.PAGE_LOAD_TIMEOUT/1000}ç§’ï¼‰")
            return None
        except Exception as e:
            log_debug(f"çˆ¬å–{operator_name}æœªçŸ¥é”™è¯¯ï¼š{str(e)}")
            print(f"âŒ è§£æé”™è¯¯ï¼š{str(e)[:100]}")
            return None
        finally:
            # ç¡®ä¿æµè§ˆå™¨å…³é—­ï¼ˆä¼˜åŒ–èµ„æºé‡Šæ”¾ï¼‰
            if 'browser' in locals():
                await browser.close()
                log_debug("æµè§ˆå™¨å·²å…³é—­")

# --- æ‰§è¡Œå…¥å£ ---
if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œä¼ å…¥å¹²å‘˜åç§°ï¼ˆä¼˜åŒ–æ˜“ç”¨æ€§ï¼‰
    import sys
    operator_name = "ç„°å½±è‹‡è‰"
    if len(sys.argv) > 1:
        operator_name = sys.argv[1]
    asyncio.run(parse_single_operator(operator_name))