import asyncio
from terms_parse import TermStaticCrawler
from operators_list_get import OperatorListCrawler
from operators_detail_parse import OperatorDetailParser
from db_handler import DBHandler
from utils import logger

def sync_terms_to_db():
    """é™æ€æœ¯è¯­çˆ¬å–â†’å…¥åº“"""
    logger.info("===== å¼€å§‹åŒæ­¥é™æ€æœ¯è¯­ =====")
    db = DBHandler()
    
    try:
        crawler = TermStaticCrawler()
        terms = crawler.run()
        if not terms:
            logger.warning("âš ï¸ æ— æœ‰æ•ˆæœ¯è¯­ï¼Œè·³è¿‡å…¥åº“")
            return
            
        if not db.connect():
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè·³è¿‡å…¥åº“")
            return
            
        if db.count_global_terms() >= len(terms):
            logger.warning("âš ï¸ æœ¯è¯­å·²å­˜åœ¨ï¼Œè·³è¿‡å…¥åº“")
            return
            
        db.insert_global_terms(terms)
        logger.info(f"âœ… æˆåŠŸå…¥åº“ {len(terms)} æ¡æœ¯è¯­")
        
    except Exception as e:
        logger.error(f"âŒ æœ¯è¯­åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
    finally:
        db.close()        

def sync_operator_list_to_db():
    """å¹²å‘˜ä¸€è§ˆçˆ¬å–â†’æ‰¹é‡å…¥åº“"""
    logger.info("===== å¼€å§‹åŒæ­¥å¹²å‘˜ä¸€è§ˆæ•°æ® =====")
    db = DBHandler()
    
    try:
        crawler = OperatorListCrawler()
        ops_list = crawler.run()
        if not ops_list:
            logger.warning("âš ï¸ æ— æœ‰æ•ˆå¹²å‘˜ä¸€è§ˆæ•°æ®ï¼Œè·³è¿‡å…¥åº“")
            return
            
        if not db.connect():
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè·³è¿‡å…¥åº“")
            return

        if db.count_operators() >= len(ops_list):
            logger.warning("âš ï¸ æ— æ–°å¢å¹²å‘˜ï¼Œè·³è¿‡å…¥åº“")
            return
        db.batch_insert_operator_base(ops_list)
        logger.info(f"âœ… æˆåŠŸå…¥åº“ {len(ops_list)} æ¡å¹²å‘˜åŸºç¡€ä¿¡æ¯")
        
    except Exception as e:
        logger.error(f"âŒ å¹²å‘˜ä¸€è§ˆåŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
    finally:
        db.close()

async def sync_operator_detail_to_db(db: DBHandler, operator_name: str):
    """å¹²å‘˜è¯¦æƒ…è§£æâ†’å…¥åº“ï¼ˆå¤ç”¨å¤–éƒ¨DBè¿æ¥ï¼Œä¿®å¤å­—æ®µå–å€¼+å®¹é”™+èµ„æºé‡Šæ”¾ï¼‰"""
    logger.info(f"===== å¼€å§‹åŒæ­¥å¹²å‘˜ {operator_name} è¯¦æƒ… =====")
    if not db or not db.connection or not db.connection.is_connected():
        logger.error(f"âŒ æ•°æ®åº“æœªè¿æ¥ï¼Œå¹²å‘˜ {operator_name} è·³è¿‡å…¥åº“")
        return False  # è¿”å›æ‰§è¡Œç»“æœï¼Œæ–¹ä¾¿ç»Ÿè®¡
    
    parser = None
    try:
        # è§£æå¹²å‘˜è¯¦æƒ…
        parser = OperatorDetailParser(operator_name)
        operator_data = await parser.run()
        if not operator_data:
            logger.warning(f"âš ï¸ å¹²å‘˜ {operator_name} è§£æå¤±è´¥ï¼Œè·³è¿‡å…¥åº“")
            return False
        
        # ========== åŸæœ‰æ ¸å¿ƒå­—æ®µéªŒè¯+å…¥åº“é€»è¾‘ï¼ˆä¸å˜ï¼‰ ==========
        # æ ¸å¿ƒå­—æ®µéªŒè¯
        if "operator_name" not in operator_data or "attributes" not in operator_data:
            logger.error(f"âŒ å¹²å‘˜ {operator_name} ç¼ºå°‘æ ¸å¿ƒå­—æ®µï¼Œè·³è¿‡å…¥åº“")
            return False
        
        # æ•´ç†å…¥åº“æ•°æ®ï¼ˆå¢åŠ å®¹é”™ï¼‰
        characteristic = operator_data.get("characteristic", {}) or {}
        attributes = operator_data.get("attributes", {}) or {}
        extra_attributes = attributes.get("extra_attributes", {}) or {}
        base_attributes = attributes.get("base_attributes", {}) or {}
        
        base_info = {
            "name_cn": operator_data["operator_name"].strip(),
            "sub_profession": characteristic.get("branch_name", ""),
            # "faction": extra_attributes.get("faction", ""),
            "hidden_faction": extra_attributes.get("hidden_faction", ""),
            "branch_description": characteristic.get("branch_description", ""),
            "trait_details": characteristic.get("trait_details", ""),
            "redployment_time": extra_attributes.get("redployment_time", ""),
            "initial_deployment_cost": extra_attributes.get("initial_deployment_cost", ""),
            "block_count": extra_attributes.get("block_count", ""),
            "attack_interval": extra_attributes.get("attack_interval", "")
        }
        
        # æ„é€ å±æ€§åˆ—è¡¨
        attr_list = []
        if isinstance(base_attributes, dict):
            for attr_type, attr_values in base_attributes.items():
                attr_values = attr_values or {}
                attr_list.append({
                    "attr_type": attr_type,
                    "max_hp": attr_values.get("max_hp", ""),
                    "atk": attr_values.get("atk", ""),
                    "def": attr_values.get("def", ""),
                    "res": attr_values.get("res", "")
                })
        
        # æ‰§è¡Œå…¥åº“æ“ä½œ - ä¸ºæ¯ä¸ªæ“ä½œåˆ›å»ºç‹¬ç«‹è¿æ¥ï¼Œé¿å…è¿æ¥å¤±æ•ˆ
        success = True
        
        # å®šä¹‰æ•°æ®åº“æ“ä½œåˆ—è¡¨
        operations = []
        
        # åŸºç¡€ä¿¡æ¯æ›´æ–°æ“ä½œ
        def update_base_info(op_db):
            update_ok = op_db.update_operator_base(base_info)
            if not update_ok:
                logger.warning(f"âš ï¸ å¹²å‘˜ {operator_name} åŸºç¡€ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰ï¼Œå°è¯•æ’å…¥")
                op_db.insert_operator_base(base_info)
            return True
        operations.append(("åŸºç¡€ä¿¡æ¯", update_base_info))
        
        # å±æ€§æ’å…¥æ“ä½œ
        if attr_list:
            operations.append(("å±æ€§", lambda op_db: op_db.insert_operator_attr(operator_name, attr_list)))
        
        # å¤©èµ‹æ’å…¥æ“ä½œ
        if "talents" in operator_data and operator_data["talents"]:
            operations.append(("å¤©èµ‹", lambda op_db: op_db.insert_operator_talent(operator_name, operator_data["talents"])))
        
        # æŠ€èƒ½æ’å…¥æ“ä½œ
        if "skills" in operator_data and operator_data["skills"]:
            operations.append(("æŠ€èƒ½", lambda op_db: op_db.insert_operator_skill(operator_name, operator_data["skills"])))
        
        # æœ¯è¯­å…³è”æ“ä½œ
        if "terms" in operator_data and operator_data["terms"]:
            term_relations = [
                {"term_name": t.get("term_name", "").strip(), "relation_module": "", "module_id": ""} 
                for t in operator_data["terms"] if t.get("term_name") and t.get("term_name").strip()
            ]
            if term_relations:
                operations.append(("æœ¯è¯­å…³è”", lambda op_db: op_db.insert_operator_term_relation(operator_name, term_relations)))
        
        # æ‰§è¡Œæ‰€æœ‰æ“ä½œ
        for op_name, op_func in operations:
            op_db = None
            try:
                op_db = DBHandler()
                if not op_db.connect():
                    logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè·³è¿‡{op_name}æ“ä½œ")
                    success = False
                    continue
                    
                result = op_func(op_db)
                if result is False:
                    logger.error(f"âŒ {op_name}æ“ä½œå¤±è´¥")
                    success = False
                else:
                    logger.debug(f"âœ… {op_name}æ“ä½œæˆåŠŸ")
                    
            except Exception as e:
                logger.error(f"âŒ {op_name}æ“ä½œå¼‚å¸¸: {str(e)[:100]}")
                success = False
            finally:
                if op_db:
                    op_db.close()
                
        if success:
            logger.info(f"âœ… å¹²å‘˜ {operator_name} è¯¦æƒ…åŒæ­¥å®Œæˆ")
        else:
            logger.warning(f"âš ï¸ å¹²å‘˜ {operator_name} éƒ¨åˆ†å­—æ®µåŒæ­¥å¤±è´¥")
        return success
        
    except Exception as e:
        logger.error(f"âŒ å¹²å‘˜ {operator_name} è¯¦æƒ…åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return False
    finally:
        # å…³é”®ï¼šå¼ºåˆ¶å…³é—­å½“å‰é¡µé¢ï¼Œé‡Šæ”¾èµ„æºï¼ˆå³ä½¿è§£æå¤±è´¥ï¼‰
        if parser and parser.page and not parser.page.is_closed():
            try:
                await parser.page.close()
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é—­å¹²å‘˜ {operator_name} é¡µé¢æ—¶è­¦å‘Šï¼š{str(e)}")

# æ‰¹é‡åŒæ­¥å¤šä¸ªå¹²å‘˜ï¼ˆå¤ç”¨DBè¿æ¥ï¼Œä¼˜åŒ–æ€§èƒ½ï¼‰
# main.py ä¸­æ‰¹é‡åŒæ­¥å‡½æ•°
async def batch_sync_operators(db: DBHandler, operator_names: list[str]):
    """æ‰¹é‡åŒæ­¥å¤šä¸ªå¹²å‘˜è¯¦æƒ…ï¼ˆæ•´åˆå…¨å±€æµè§ˆå™¨å¤ç”¨+å´©æºƒæ¢å¤+å»¶è¿Ÿä¼˜åŒ–ï¼‰"""
    if not operator_names:
        logger.warning("âš ï¸ å¹²å‘˜åç§°åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æ‰¹é‡åŒæ­¥")
        return 0
    
    # ========== åˆå§‹åŒ–å…¨å±€æµè§ˆå™¨ï¼ˆæå‰åˆ›å»ºï¼Œé¿å…é¦–æ¬¡çˆ¬å–æ—¶åˆå§‹åŒ–ï¼‰ ==========
    try:
        await OperatorDetailParser.init_shared_browser()
    except Exception as e:
        logger.error(f"âŒ å…¨å±€æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ‰¹é‡åŒæ­¥ç»ˆæ­¢ï¼š{str(e)}")
        return 0
    
    # ========== æ•°æ®åº“é•¿è¿æ¥æ£€æŸ¥ ==========
    if not db.connect():
        await OperatorDetailParser.close_shared_browser()
        return 0
    
    logger.info(f"===== å¼€å§‹æ‰¹é‡åŒæ­¥ {len(operator_names)} ä¸ªå¹²å‘˜è¯¦æƒ… =====")
    success_count = 0
    valid_names = [name.strip() for name in operator_names if name and name.strip()]
    
    for i, name in enumerate(valid_names, 1):
        # å…³é”®1ï¼šæ¯çˆ¬å–20ä¸ªå¹²å‘˜ï¼Œé‡å¯ä¸€æ¬¡æµè§ˆå™¨ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰
        if i % 20 == 0:
            logger.info(f"\nğŸ”„ çˆ¬å–è¾¾20ä¸ªå¹²å‘˜ï¼Œé‡å¯æµè§ˆå™¨é‡Šæ”¾å†…å­˜...")
            await OperatorDetailParser.close_shared_browser()
            await asyncio.sleep(5)
            await OperatorDetailParser.init_shared_browser()
        
        try:
            logger.info(f"è¿›åº¦: {i}/{len(valid_names)} - å¼€å§‹åŒæ­¥ {name}")
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥ï¼ˆå¤±æ•ˆåˆ™é‡è¿ï¼‰
            if not db.is_connected():
                logger.warning(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±æ•ˆï¼Œå°è¯•é‡è¿...")
                if not db.reconnect():
                    logger.error(f"âŒ æ•°æ®åº“é‡è¿å¤±è´¥ï¼Œè·³è¿‡å¹²å‘˜ {name}")
                    continue
            
            # æ‰§è¡ŒåŒæ­¥ï¼ˆå¢åŠ å•æ¬¡å¤±è´¥é‡è¯•ï¼‰
            sync_retry = 0
            sync_success = False
            while sync_retry < 2 and not sync_success:
                try:
                    sync_success = await sync_operator_detail_to_db(db, name)
                except Exception as e:
                    error_msg = str(e).lower()
                    if "closed" in error_msg or "crashed" in error_msg:
                        logger.warning(f"âš ï¸ å¹²å‘˜ {name} åŒæ­¥å¤±è´¥ï¼ˆæµè§ˆå™¨å´©æºƒï¼‰ï¼Œé‡è¯• ({sync_retry+1}/2)")
                        await OperatorDetailParser.close_shared_browser()
                        await asyncio.sleep(5)
                        await OperatorDetailParser.init_shared_browser()
                    sync_retry += 1
                    await asyncio.sleep(2)
            
            if sync_success:
                success_count += 1
        
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åŒæ­¥ä¸­å¹²å‘˜ {name} å¤±è´¥: {str(e)}", exc_info=True)
            # å¼‚å¸¸åé‡ç½®é¡µé¢ï¼Œé¿å…å½±å“ä¸‹ä¸€ä¸ª
            continue
        finally:
            # å…³é”®2ï¼šå¢åŠ çˆ¬å–é—´éš”ï¼ˆå»¶é•¿åˆ°3ç§’ï¼Œé™ä½æµè§ˆå™¨å‹åŠ›ï¼‰
            if i < len(valid_names):
                await asyncio.sleep(3)  # æ ¸å¿ƒï¼šä»1.5ç§’å»¶é•¿åˆ°3ç§’
    
    # ========== æ‰¹é‡ç»“æŸåæ¸…ç†èµ„æº ==========
    logger.info(f"===== æ‰¹é‡åŒæ­¥å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(valid_names)} =====")
    await OperatorDetailParser.close_shared_browser()  # å…³é—­å…¨å±€æµè§ˆå™¨
    db.close()  # å…³é—­æ•°æ®åº“é•¿è¿æ¥
    return success_count

def sync_operators_detail():
    """åŒæ­¥å¹²å‘˜ä¸€è§ˆâ†’æ‰¹é‡åŒæ­¥å¹²å‘˜è¯¦æƒ…ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šDBè¿æ¥å¤ç”¨ï¼‰"""
    logger.info("===== å¼€å§‹åŒæ­¥å¹²å‘˜è¯¦æƒ… =====")
    db = DBHandler()
    success_count = 0
    valid_names = []
    
    try:          
        # 1. å•æ¬¡åˆ›å»ºDBè¿æ¥ï¼Œå¤ç”¨æ•´ä¸ªæ‰¹é‡åŒæ­¥æµç¨‹
        if not db.connect():
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œè·³è¿‡å…¥åº“")
            return
        
        # 2. æå–æœ‰æ•ˆå¹²å‘˜åç§°ï¼ˆä¿®å¤å…ƒç»„è½¬å­—ç¬¦ä¸²ï¼‰
        operators = db.select_all_operators()
        if not operators:
            logger.warning("âš ï¸ æ— æœ‰æ•ˆå¹²å‘˜ä¸€è§ˆæ•°æ®ï¼Œè·³è¿‡å…¥åº“")
            return
        
        # å‡è®¾operator_baseè¡¨ä¸­name_cnæ˜¯ç¬¬äºŒä¸ªå­—æ®µï¼ˆç´¢å¼•1ï¼‰ï¼Œæ ¹æ®å®é™…è¡¨ç»“æ„è°ƒæ•´
        for op in operators:
            try:
                if len(op) >= 2 and op[1] and op[1].strip():
                    valid_names.append(op[1].strip())
            except:
                continue
        
        if not valid_names:
            logger.warning("âš ï¸ æ— æœ‰æ•ˆå¹²å‘˜åç§°ï¼Œè·³è¿‡åŒæ­¥")
            return
            
        # 3. æ‰¹é‡åŒæ­¥ï¼ˆå¤ç”¨DBè¿æ¥ï¼‰
        success_count = asyncio.run(batch_sync_operators(db, valid_names))
        
    except Exception as e:
        logger.error(f"âŒ å¹²å‘˜è¯¦æƒ…åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
    finally:
        # 4. ç»Ÿä¸€å…³é—­DBè¿æ¥ï¼ˆæ— è®ºæˆåŠŸå¤±è´¥ï¼‰
        try:
            db.close()
        except:
            pass
    
    logger.info(f"===== å¹²å‘˜è¯¦æƒ…åŒæ­¥æ€»è§ˆï¼šæˆåŠŸ {success_count}/{len(valid_names)} =====")

if __name__ == "__main__":
    # å¯é€‰æ‰§è¡Œé¡ºåºï¼ˆæŒ‰éœ€æ³¨é‡Š/å–æ¶ˆæ³¨é‡Šï¼‰
    # 1. åŒæ­¥å¹²å‘˜ä¸€è§ˆï¼ˆæ‰¹é‡å…¥åº“åŸºç¡€ä¿¡æ¯ï¼‰
    sync_operator_list_to_db()
    
    # 2. åŒæ­¥é™æ€æœ¯è¯­ï¼ˆå…ˆäºå¹²å‘˜è¯¦æƒ…åŒæ­¥ï¼‰
    sync_terms_to_db()

    # 3. åŒæ­¥æ‰€æœ‰å¹²å‘˜è¯¦æƒ…ï¼ˆå¤ç”¨DBè¿æ¥ï¼Œä¼˜åŒ–æ€§èƒ½ï¼‰
    sync_operators_detail()
    
    # 4. æ‰‹åŠ¨æ‰¹é‡åŒæ­¥å¤šä¸ªå¹²å‘˜ï¼ˆå¤ç”¨DBè¿æ¥ï¼‰
    # db = DBHandler()
    # if db.connect():
    #     asyncio.run(batch_sync_operators(db, ["ç„°å½±è‹‡è‰", "ä»¤", "æµŠå¿ƒæ–¯å¡è’‚"]))
    #     db.close()