import re
import asyncio
from playwright.async_api import async_playwright
from db_utils import DBHandler

# é…ç½®é¡¹
CONFIG = {
    "BASE_URL": "https://prts.wiki",  # PRTSç»´åŸºåœ°å€
    "HEADLESS": True,  # æ— å¤´æ¨¡å¼ï¼ˆFalseå¯çœ‹åˆ°æµè§ˆå™¨æ“ä½œï¼‰
    "PAGE_LOAD_TIMEOUT": 30000,  # é¡µé¢åŠ è½½è¶…æ—¶30s
    "OPERATORS_MD_PATH": "operators.md"  # å¹²å‘˜åˆ—è¡¨mdæ–‡ä»¶è·¯å¾„
}

def parse_operators_md(file_path=None):
    """ä»operators.mdæå–å¹²å‘˜åŸºç¡€åˆ—è¡¨ï¼ˆé€‚é…æ–°è¡¨å­—æ®µï¼‰"""
    file_path = file_path or CONFIG["OPERATORS_MD_PATH"]
    operators = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # åŒ¹é…Markdownè¡¨æ ¼è¡Œï¼ˆæ ¼å¼ï¼š| ä¸­æ–‡å | ç¨€æœ‰åº¦ | èŒä¸š | åˆ†æ”¯ | é˜µè¥ | æ€§åˆ« | ä½ç½® | æ ‡ç­¾ |ï¼‰
        pattern = r"\| (.*?) \| (.*?) \| (.*?) \| (.*?) \| (.*?) \| (.*?) \| (.*?) \| (.*?) \|"
        matches = re.findall(pattern, content)
        
        for row in matches:
            if row[0] in ["ä¸­æ–‡å", "", "â€”"]:  # è·³è¿‡è¡¨å¤´/ç©ºè¡Œ/åˆ†éš”ç¬¦
                continue
            # æå–å­—æ®µå¹¶æ¸…æ´—
            name = row[0].strip()
            if not name:
                continue
            operators.append({
                "name": name,
                "rarity": row[1].strip(),
                "profession": row[2].strip(),
                "branch": row[3].strip(),
                "faction": row[4].strip(),
                "gender": row[5].strip(),
                "position": row[6].strip(),
                "tags": [t.strip() for t in row[7].split() if t.strip()]
            })
        print(f"ğŸ“‹ ä»{file_path}æå–åˆ° {len(operators)} åå¹²å‘˜")
        return operators
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°{file_path}æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return []
    except Exception as e:
        print(f"âŒ è§£æoperators.mdå¤±è´¥: {str(e)}")
        return []

async def parse_single_operator(page, operator_name):
    """è§£æå•ä¸ªå¹²å‘˜çš„è¯¦ç»†ä¿¡æ¯ï¼ˆé€‚é…æ–°è¡¨å­—æ®µï¼‰"""
    operator_name = operator_name.strip()
    if not operator_name:
        return None
    
    url = f"{CONFIG['BASE_URL']}/w/{operator_name}"
    try:
        await page.goto(url, wait_until="domcontentloaded", timeout=CONFIG["PAGE_LOAD_TIMEOUT"])
        await page.wait_for_selector("#mw-content-text", timeout=CONFIG["PAGE_LOAD_TIMEOUT"])
        
        # 1. è§£æèŒä¸šåˆ†æ”¯/ç‰¹æ€§ï¼ˆé€‚é…operatorsè¡¨ï¼‰
        branch_name = await page.locator("div[data-source='branch'] .pi-data-value").text_content() or ""
        branch_desc = await page.locator("div[data-source='branch_desc'] .pi-data-value").text_content() or ""
        trait_details = await page.locator("div[data-source='trait'] .pi-data-value").text_content() or ""
        
        # 2. è§£æåŸºç¡€å±æ€§ï¼ˆé€‚é…operator_attributesè¡¨ï¼‰
        attr_list = []
        attr_rows = await page.locator("table.wikitable:has(th:has-text('ç²¾è‹±ç­‰çº§')) tr").all()
        for row in attr_rows[1:]:  # è·³è¿‡è¡¨å¤´
            cols = await row.locator("td").all()
            if len(cols) < 5:
                continue
            elite_level = await cols[0].text_content() or ""
            max_hp = await cols[1].text_content() or ""
            atk = await cols[2].text_content() or ""
            def_val = await cols[3].text_content() or ""
            res = await cols[4].text_content() or ""
            attr_list.append({
                "elite_level": elite_level.strip(),
                "max_hp": max_hp.strip(),
                "atk": atk.strip(),
                "def": def_val.strip(),
                "res": res.strip()
            })
        
        # 3. è§£æé¢å¤–å±æ€§ï¼ˆé€‚é…operator_extra_attrsè¡¨ï¼‰
        extra_attr = {
            "redeployment_time": await page.locator("div[data-source='redeployment'] .pi-data-value").text_content() or "",
            "initial_deployment_cost": await page.locator("div[data-source='cost'] .pi-data-value").text_content() or "",
            "attack_interval": await page.locator("div[data-source='attack_interval'] .pi-data-value").text_content() or "",
            "block_count": await page.locator("div[data-source='block'] .pi-data-value").text_content() or "",
            "hidden_faction": await page.locator("div[data-source='hidden_faction'] .pi-data-value").text_content() or ""
        }
        # æ¸…æ´—é¢å¤–å±æ€§å€¼
        for k, v in extra_attr.items():
            extra_attr[k] = v.strip()
        
        # 4. è§£æå¤©èµ‹ï¼ˆé€‚é…operator_talents/talent_detailsè¡¨ï¼‰
        talents = []
        talent_blocks = await page.locator("div[data-source='talent'] .pi-data-value").all()
        for idx, block in enumerate(talent_blocks):
            talent_html = await block.inner_html()
            # ç®€æ˜“è§£æï¼ˆå¯æ ¹æ®PRTSé¡µé¢ç»“æ„ç»†åŒ–ï¼‰
            talents.append({
                "talent_type": f"ç¬¬{idx+1}å¤©èµ‹",
                "talent_name": await block.locator("b").text_content() or "",
                "trigger_condition": "",
                "description": await block.text_content() or "",
                "potential_enhancement": "",
                "remarks": ""
            })
        
        # 5. è§£ææŠ€èƒ½ï¼ˆé€‚é…operator_skills/skill_levelsè¡¨ï¼‰
        skills = []
        skill_blocks = await page.locator("div[data-source='skill'] .pi-data-value").all()
        for idx, block in enumerate(skill_blocks):
            skill_name = await block.locator("b").text_content() or ""
            # è§£ææŠ€èƒ½ç­‰çº§ï¼ˆç®€æ˜“ç‰ˆï¼‰
            levels = [
                {
                    "level": "7",
                    "initial_sp": "0",
                    "sp_cost": "30",
                    "duration": "20s",
                    "description": await block.text_content() or ""
                }
            ]
            skills.append({
                "skill_number": idx+1,
                "skill_name": skill_name.strip(),
                "skill_type": "",
                "unlock_condition": "",
                "remarks": "",
                "levels": levels
            })
        
        # æ•´åˆæ‰€æœ‰æ•°æ®
        return {
            "branch_name": branch_name.strip(),
            "branch_description": branch_desc.strip(),
            "trait_details": trait_details.strip(),
            "attributes": attr_list,
            "extra_attrs": extra_attr,
            "talents": talents,
            "skills": skills
        }
    except Exception as e:
        print(f"âŒ è§£æ{operator_name}è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

async def batch_parse_and_save(operators, db_handler):
    """æ‰¹é‡è§£æå¹²å‘˜å¹¶å­˜å‚¨åˆ°æ•°æ®åº“"""
    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆé¿å…é‡å¤å¯åŠ¨ï¼‰
        browser = await p.chromium.launch(
            headless=CONFIG["HEADLESS"],
            args=["--no-sandbox", "--disable-blink-features=AutomationControlled"]
        )
        context = await browser.new_context()
        page = await context.new_page()
        
        # é€ä¸ªè§£æ
        success_count = 0
        fail_count = 0
        for idx, op_base in enumerate(operators, 1):
            print(f"\n===== å¤„ç†ç¬¬ {idx}/{len(operators)} åå¹²å‘˜: {op_base['name']} =====")
            
            # 1. æ’å…¥åŸºç¡€ä¿¡æ¯
            operator_id = db_handler.insert_operator_base(op_base)
            if not operator_id:
                fail_count += 1
                continue
            
            # 2. è§£æè¯¦ç»†ä¿¡æ¯
            op_detail = await parse_single_operator(page, op_base["name"])
            if not op_detail:
                fail_count += 1
                continue
            
            # 3. è¡¥å……åŸºç¡€ä¿¡æ¯çš„åˆ†æ”¯/ç‰¹æ€§å­—æ®µ
            op_base.update({
                "branch_name": op_detail["branch_name"],
                "branch_description": op_detail["branch_description"],
                "trait_details": op_detail["trait_details"]
            })
            # é‡æ–°æ’å…¥ï¼ˆè¦†ç›–ç©ºå€¼ï¼‰
            db_handler.insert_operator_base(op_base)
            
            # 4. æ’å…¥å„ç»´åº¦æ•°æ®
            db_handler.insert_operator_attributes(operator_id, op_detail["attributes"])
            db_handler.insert_operator_extra_attrs(operator_id, op_detail["extra_attrs"])
            db_handler.insert_operator_talents(operator_id, op_detail["talents"])
            db_handler.insert_operator_skills(operator_id, op_detail["skills"])
            
            success_count += 1
        
        # å…³é—­æµè§ˆå™¨
        await browser.close()
        print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼šæˆåŠŸ{success_count}ä¸ªï¼Œå¤±è´¥{fail_count}ä¸ª")

if __name__ == "__main__":
    # 1. åˆå§‹åŒ–æ•°æ®åº“
    db = DBHandler()
    if not db.connect():
        exit(1)
    
    try:
        # 2. æå–å¹²å‘˜åˆ—è¡¨
        all_operators = parse_operators_md()
        if not all_operators:
            print("âŒ æœªæå–åˆ°å¹²å‘˜åˆ—è¡¨ï¼Œé€€å‡º")
            exit(1)
        
        # 3. æ‰¹é‡è§£æå¹¶å­˜å‚¨
        asyncio.run(batch_parse_and_save(all_operators, db))
    finally:
        # 4. å…³é—­æ•°æ®åº“è¿æ¥
        db.close()